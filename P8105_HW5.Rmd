---
title: "P8105 HW5"
author: "Veerapetch Petchger"
date: "2025-10-31"
output: github_document
---
```{r setup, include = FALSE}
library(tidyverse)
library(rvest)
set.seed(1)
```

# Problem 1
**Suppose you put ð‘› people in a room, and want to know the probability that at least two people share a birthday. For simplicity, weâ€™ll assume there are no leap years (i.e. there are only 365 days) and that birthdays are uniformly distributed over the year (which is actually not the case).**

**Write a function that, for a fixed group size, randomly draws â€œbirthdaysâ€ for each person; checks whether there are duplicate birthdays in the group; and returns TRUE or FALSE based on the result.**

```{r birthday_function}
shared_birthday = function(group_size) {
  
  birthdays = sample(1:365, group_size, replace = TRUE)
  length(birthdays) != length(unique(birthdays))
 
}
```

**Next, run this function 10000 times for each group size between 2 and 50. For each group size, compute the probability that at least two people in the group will share a birthday by averaging across the 10000 simulation runs. Make a plot showing the probability as a function of group size, and comment on your results.**

```{r birthday_simulation}
birthday_df =
  tibble(group_size = 2:50) %>% 
  mutate(shared_birthday_prob = map_dbl(
    group_size,
    ~ mean((replicate(10000, shared_birthday(.x)))
  )))

birthday_df %>% 
  ggplot(aes(x = group_size, y = shared_birthday_prob, fill = shared_birthday_prob)) +
  geom_col() + 
  labs(
    title = "Probability of Shared Birthdays with Respect to Group Size",
    x = "Group Size",
    y = "Probability"
  ) +
  viridis::scale_fill_viridis() +
  theme_minimal()
```
The probability of a shared birthday has a positive exponential relationship with group size. At a group size of 23, the probability of a shared birthday is approximately 50%, and caps at `r birthday_df %>% filter(group_size == 50) %>% pull(shared_birthday_prob)`.

# Problem 2
**When designing an experiment or analysis, a common question is whether it is likely that a true effect will be detected â€“ put differently, whether a false null hypothesis will be rejected. The probability that a false null hypothesis is rejected is referred to as power, and it depends on several factors, including: the sample size; the effect size; and the error variance. In this problem, you will conduct a simulation to explore power in a one-sample t-test.**
 
**First set the following design elements**

- Fix ð‘›=30
- Fix ðœŽ=5

**Generate 5000 datasets from the model**

ð‘¥âˆ¼ð‘ð‘œð‘Ÿð‘šð‘Žð‘™[ðœ‡,ðœŽ] 

**For each dataset, save ðœ‡Ì‚ and the p-value arising from a test of ð»:ðœ‡=0 using ð›¼=0.05. Hint: to obtain the estimate and p-value, use broom::tidy to clean the output of t.test.**

**Repeat the above for ðœ‡={1,2,3,4,5,6}, and complete the following:**

```{r problem2_function, warning = FALSE}
set.seed(1)
power_t = function(n = 30, sigma = 5, mu = 0, mu_hat = 0) {
  
  power_df = 
    tibble(
      x = rnorm(n, mu, sigma)
    )
  
  samp_mean = 
    power_df %>% 
    summarize(
      mu_hat = mean(x),
      p_val = t.test(x, mu = 0) %>%
        broom::tidy() %>% 
        pull(p.value)
    )
  
  return(samp_mean)
}

results_mu0 = 
  rerun(5000, power_t(n = 30, sigma = 5, mu = 0, mu_hat = 0 )) %>% 
  bind_rows()

mu_vals = 0:6

power_results = 
  tibble(true_mean = mu_vals) %>% 
  mutate(
    power_df = map(
      true_mean, ~rerun(5000, power_t(n = 30, sigma = 5, mu = .x, mu_hat = 0 )) %>%
        bind_rows()
  )) %>%
  unnest(power_df)
```

**- Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of ðœ‡ on the x axis. Describe the association between effect size and power.**
```{r, power_vs_true_mu}
power_results %>% 
  mutate(
    reject = p_val < 0.05
  ) %>% 
  group_by(true_mean) %>% 
  summarize(
    power = mean(reject),
    .groups = "drop"
  ) %>% 
  ggplot(aes(x = true_mean, y = power)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Power for One Sample t-test, n = 30, sd = 5",
    x = "True mean",
    y = "Power"
  ) +
  theme_minimal()
  
```
Power has a positive relationship with ðœ‡ values further from the null. When ðœ‡ = 0, the effect size is relatively small with respect to the standard deviation, leaving the power low and the t-test often failing to rejct the null. As ðœ‡ increases, the difference to 0 becomes easier to detect, yielding more rejection of the null. By ðœ‡ = 4, power approaches 1, meaning that it almost always detects the effect.  

**- Make a plot showing the average estimate of ðœ‡Ì‚ on the y axis and the true value of ðœ‡ on the x axis. Make a second plot (or overlay on the first) the average estimate of ðœ‡Ì‚ only in samples for which the null was rejected on the y axis and the true value of on the x axis. Is the sample average of ðœ‡Ì‚ across tests for which the null is rejected approximately equal to the true value of ðœ‡? Why or why not?**
```{r true_mu_vs_avg_mu_hat}
power_results %>% 
  mutate(
    reject = p_val < 0.05
  ) %>%
  group_by(true_mean) %>% 
  summarize(
    avg_mu_hat = mean(mu_hat),
    avg_reject = mean(mu_hat[reject]),
    .groups = "drop"
  ) %>% 
  pivot_longer(
    cols = c(avg_mu_hat, avg_reject),
    names_to = "type",
    values_to = "estimate"
  ) %>% 
  ggplot(aes(x = true_mean, y = estimate, color = type)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Average Estimate of Mean vs True Mean",
    x = "True Mean",
    y = "Average Estimate of Mean"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom") +
  viridis::scale_color_viridis(discrete = TRUE)
```
No, the conditional mean of ðœ‡^ when the null is rejected is biased upwards and away from 0. This selective filtering only keeps the most significant means. Overall ðœ‡^ itself is unbiased, but not under the condition that the null is rejected.

# Problem 3
**The Washington Post has gathered data on homicides in 50 large U.S. cities and made the data available through a GitHub repository here. You can read their accompanying article here.**

**Describe the raw data. Create a city_state variable (e.g. â€œBaltimore, MDâ€) and then summarize within cities to obtain the total number of homicides and the number of unsolved homicides (those for which the disposition is â€œClosed without arrestâ€ or â€œOpen/No arrestâ€).**
```{r unsolved_homicides}
homicide_df = 
  read.csv("homicide-data.csv") 

homicide_df %>% 
  janitor::clean_names() %>% 
  mutate(
    city_state = str_c(city, ", ", state),
    unsolved = disposition %in% c("Closed without arrest", "Open/No arrest")
  ) %>% 
  group_by(city_state) %>% 
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(unsolved),
    .groups = "drop"
  ) %>% 
  knitr::kable(caption = "Summary of Total and Unsolved Homicides by City")
```
The raw dataset contains information about homicides collected by the The Washington Post from the police departments of the 50 largest American cities. Each row pertains to a particular homicide, with `r nrow(homicide_df)` observations and `r ncol(homicide_df)` variables. Variables include the victim's demographics, date and location of homicide, and case status. The case status is noted by `disposition`, indicating whether or the case was solved.

**For the city of Baltimore, MD, use the prop.test function to estimate the proportion of homicides that are unsolved; save the output of prop.test as an R object, apply the broom::tidy to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.**
```{r baltimore}
bmore_tidy =
  homicide_df %>% 
  janitor::clean_names() %>% 
  mutate(
    city_state = str_c(city, ", ", state),
    unsolved = disposition %in% c("Closed without arrest", "Open/No arrest")
  ) %>% 
  filter(city_state == "Baltimore, MD") %>%  
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(unsolved),
    .groups = "drop"
  ) %>% 
{prop.test(.$unsolved_homicides, .$total_homicides)} %>% 
  broom::tidy() 

bmore_tidy %>% 
  select(estimate, conf.low, conf.high) %>% 
  knitr::kable(caption = "Estimated Proportion of Unsolved Homicides in Baltimore, MD")
```
The estimated proportion of unsolved homicides in Baltimore, MD is `r bmore_tidy %>% pull(estimate)`, with a 95% confidence interval from (`r bmore_tidy %>% pull(conf.low)`, `r bmore_tidy %>% pull(conf.high)`).

**Now run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Do this within a â€œtidyâ€ pipeline, making use of purrr::map, purrr::map2, list columns and unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.**
```{r unsolved, warning = FALSE}
homicide_df %>% 
  janitor::clean_names() %>% 
  mutate(
    city_state = str_c(city, ", ", state),
    unsolved = disposition %in% c("Closed without arrest", "Open/No arrest")
  ) %>%
  group_by(city_state) %>% 
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(unsolved),
    .groups = "drop"
  ) %>% 
  mutate(
    prop_test = purrr::map2(unsolved_homicides, total_homicides, ~ prop.test(.x, .y)),
    prop_tidy = purrr::map(prop_test, broom::tidy)
  ) %>% 
  unnest(prop_tidy) %>% 
  select(city_state, estimate, conf.low, conf.high) %>% 
  knitr::kable(caption = "Estimated Proportion of Unsolved Homicidies in the U.S.' 50 Largest Cities")
```

Create a plot that shows the estimates and CIs for each city â€“ check out geom_errorbar for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.
```{r}

```


